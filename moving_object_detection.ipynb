{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dea49934",
      "metadata": {
        "id": "dea49934",
        "outputId": "f26f9c38-ca36-4fe0-b30f-af94aebf8d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected object: person with confidence 0.98\n",
            "Detected object: cat with confidence 0.52\n",
            "Detected object: bottle with confidence 0.75\n",
            "Detected object: person with confidence 0.85\n",
            "Detected object: sofa with confidence 0.66\n",
            "Detected object: cat with confidence 0.74\n",
            "Detected object: cat with confidence 0.59\n",
            "Detected object: car with confidence 0.52\n",
            "Detected object: cat with confidence 0.54\n",
            "Detected object: bottle with confidence 0.51\n",
            "Detected 10 objects, stopping execution...\n",
            "Detected object: tvmonitor with confidence 0.87\n",
            "Detected 10 objects, stopping execution...\n",
            "Detected object: bottle with confidence 0.58\n",
            "Detected 10 objects, stopping execution...\n",
            "Program execution stopped.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained model and class labels\n",
        "net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'mobilenet_iter_73000.caffemodel')\n",
        "classes = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',\n",
        "           'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant',\n",
        "           'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "# Initialize the video capture object\n",
        "cap = cv2.VideoCapture(0)  # 0 for webcam, or provide a video file path\n",
        "\n",
        "# Initialize the background subtractor\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "# Counter for detected objects\n",
        "object_count = 0\n",
        "max_objects = 10  # Number of objects to detect before stopping\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Apply the background subtractor to get the foreground mask\n",
        "    fgmask = fgbg.apply(frame)\n",
        "\n",
        "    # Find contours in the mask\n",
        "    contours, _ = cv2.findContours(fgmask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) < 500:\n",
        "            continue\n",
        "\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        # Extract the region of interest (ROI)\n",
        "        roi = frame[y:y+h, x:x+w]\n",
        "\n",
        "        # Prepare the ROI for classification\n",
        "        blob = cv2.dnn.blobFromImage(roi, 0.007843, (300, 300), 127.5)\n",
        "        net.setInput(blob)\n",
        "        detections = net.forward()\n",
        "\n",
        "        # Loop through the detected objects in the ROI\n",
        "        for i in range(detections.shape[2]):\n",
        "            confidence = detections[0, 0, i, 2]\n",
        "            if confidence > 0.5:  # Confidence threshold\n",
        "                idx = int(detections[0, 0, i, 1])\n",
        "                label = classes[idx]\n",
        "                label_text = f\"{label}: {confidence:.2f}\"\n",
        "\n",
        "                # Draw bounding box and label on the original frame\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, label_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "                # Print the detected object\n",
        "                print(f\"Detected object: {label} with confidence {confidence:.2f}\")\n",
        "\n",
        "                # Increment the object counter\n",
        "                object_count += 1\n",
        "\n",
        "                # Check if the object count has reached the maximum\n",
        "                if object_count >= max_objects:\n",
        "                    print(\"Detected 10 objects, stopping execution...\")\n",
        "                    break  # Break the inner loop\n",
        "\n",
        "    # Check if we should break the outer loop as well\n",
        "    if object_count >= max_objects:\n",
        "        break\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Frame', frame)\n",
        "    cv2.imshow('Foreground Mask', fgmask)\n",
        "\n",
        "    # Exit on pressing 'q'\n",
        "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Properly release the video capture object and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Program execution stopped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2270d9",
      "metadata": {
        "id": "9e2270d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbff4701",
      "metadata": {
        "id": "fbff4701"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}